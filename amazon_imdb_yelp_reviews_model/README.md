## CUSTOMER REVIEWS BERT MODEL

### Overview:
In this repository I have push a Deep learning model notebook which I have trained in **BERT(Bidirectional Encoder Representations from Transformers)** to get the richest results for the **NLP(Natural Language Processing)** Tasks. 

The Kaggle Dataset can be found here : https://www.kaggle.com/xaviholt/sentimentanalysis    
on which I have applied Text cleaning techniques to clean the data and then preprocess the data for BERT and built the model with **Tensorflow 2.0**.
